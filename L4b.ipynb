{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cwiczenie [3 pkt]\n",
    "\n",
    "Proszę :\n",
    "    1. Zapisać model Naive Bayes w notacji jak powyżej\n",
    "    2. Wyprowadzić wzór na MLE w modelu Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W modelu Naive Bayes, otrzymawszy wektor cech $\\mathbf{x}$ musimy sklasyfikować z jakiej klasy $y_{k}$ pochodzą te cechy. \n",
    "\n",
    "Zgodnie ze wzorem Bayesa mamy:\n",
    "\n",
    "$$ P(y_{k} \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x}\\mid y_{k})\\,P(y_{k})}{P(\\mathbf{x})} $$\n",
    "\n",
    "Mianownik powyższego wyrażenia nie zależy od $y_{k}$, a licznik można rozpisać jako:\n",
    "\n",
    "$$ P(\\mathbf{x}\\mid y_{k})) =  P(\\mathbf{x},y_{k}) = P(x_{0},x_{1},,...,x_{n},y_{k}), $$\n",
    "\n",
    "co z kolei rozwija się teleskopowo:\n",
    "\n",
    "$$ P(x_{0},x_{1},,...,x_{n},y_{k}) = P(x_{0}\\mid x_{1},,...,x_{n},y_{k})P(x_{1},,...,x_{n},y_{k}) = ... = P(x_{0} \\mid x_{1},,...,x_{n},y_{k})...P(x_{n} \\mid y_{k}) P(y_{k}). $$\n",
    "\n",
    "Zakładając teraz naiwnie, że cechy z $\\mathbf{x}$ są warunkowo niezależne, tzn. dla dowolnego $i$ mamy:\n",
    "\n",
    "$$P(x_{i}\\mid x_{i+1},,...,x_{n},y_{k}) = P(x_{i}\\mid ,y_{k}),$$\n",
    "\n",
    "Więc nasz likelihood to:\n",
    "\n",
    "$$ \\prod_{i=0}^{n}P(x_{i} \\mid y_{k}) $$\n",
    "\n",
    "możemy ostatecznie zapisać:\n",
    "\n",
    "$$ P(y_{k} \\mid \\mathbf{x})  = \\frac{P(x_{0} \\mid y_{k})...P(x_{n} \\mid y_{k}) P(y_{k})}{P(\\mathbf{x})}  = \\frac{P(y_{k})\\prod_{i=0}^{n}P(x_{i} \\mid y_{k})}{P(\\mathbf{x})}$$\n",
    "\n",
    "\n",
    "MLE otrzymujemy znajdując klasę maksymalizującą powyższe wyrażenie ze względu na $y_{k}$ zakładając jednostajny prior, stąd też upraszczając powyższe mamy:\n",
    "\n",
    "$$\\hat{y} = \\underset{k \\in \\{1, \\dots, K\\}}{\\operatorname{argmax}} \\  \\displaystyle\\prod_{i=1}^n p(x_i \\mid y_k)$$\n",
    "\n",
    "\n",
    "Jeśli założymy, ze klasy $y_{k}$ oznaczają rozkłady Bernoullego dla różnych parametrów $\\theta_{k}$, możemy zapisać MLE jako:\n",
    "\n",
    "$$ \\hat{y} = \\underset{k \\in \\{1, \\dots, K\\}}{\\operatorname{argmax}} \\ \\prod_{i=1}^n \\theta_{k}^{x_i} (1 - \\theta_{k})^{(1-x_i)} $$\n",
    "\n",
    "Standardowo maksymalizujemy likelihood. Nie możemy jednak, jak czyniliśmy wcześniej, znaleźć maksimum wielomianu równego ilorazowi sumy sukcesów i wszystkich prób. Jako że nasza przestrzeń klas jest skończona, możemy jedynie sprawdzić jego wartość w punktach którymi dysponujemy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
